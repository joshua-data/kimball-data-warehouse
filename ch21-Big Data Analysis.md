# Chapter 21. 빅데이터 분석 - 학습 노트

---

## 1. 개요

- 이번 장에서는 **빅데이터란 무엇인지**, 그리고 빅데이터가 전통적인 DW/BI 시스템에 어떻게 확장되고 기여할 수 있는지를 다룹니다.
- 또한, 빅데이터 분석을 지원하는 두 가지 주요 아키텍처(확장된 RDBMS, 맵리듀스/하둡)를 비교하고,
- 빅데이터 관리, 아키텍처, 모델링, 거버넌스에서의 우수 사례를 소개합니다.

---

## 2. 빅데이터란?

- 단순히 ‘크다’는 의미를 넘어서,
- **정형, 반정형, 비정형, 원시 데이터** 등 다양한 형태의 데이터를 포함합니다.
- 기존 30년간 저장해온 깔끔한 숫자/텍스트 데이터와는 매우 다릅니다.
- **SQL 같은 전통적인 질의 언어로는 분석이 불가능한 경우가 많음**
- 빅데이터의 핵심은 데이터 자산 개념과 이를 통한 비즈니스 인사이트 창출이라는 **패러다임 전환**입니다.

---

## 3. 빅데이터 활용 방안 사례

다양한 산업 분야에서 빅데이터 분석이 활용됩니다. 주요 활용 예시는 다음과 같습니다.

- 검색 결과 랭킹
- 광고 추적
- 위치 및 근접성 추적
- 원인 인자 발견
- 소셜 CRM
- 문서 간 유사성 검사
- 유전자 분석
- 동질 그룹 찾기
- 비행기 상태 모니터링
- 스마트 계측기, 빌딩 센서
- 위성 이미지 비교
- 의료 영상 비교 (CT 등)
- 금융 사기 및 해킹 탐지
- 온라인 게임 활동 추적
- 대규모 과학 데이터 분석
- 키-값 구조 분석
- 대출 및 보험 리스크 분석
- 고객 이탈 분석

---

## 4. 빅데이터 시스템이 갖춰야 할 조건 (도전 과제)

빅데이터를 효과적으로 활용하기 위해서는 시스템이 다음 요구사항을 충족해야 합니다.

1. **페타바이트(PB) 규모 데이터 확장 가능성**
2. 지리적으로 분산된 수천 개 CPU에서의 분산 처리
3. 원형 데이터 그대로 저장 및 분석 (ETL 최소화)
4. SQL 질의에 대해 1초 이내 응답
5. 사용자 정의 함수 내장 및 실행 가능
6. 절차적 언어로 사용자 함수 작성 지원
7. 함수 조합 및 라이브러리화 가능
8. 대용량 데이터에 사용자 정의 함수 실행 후 수분 내 결과 도출
9. 이미지, 파형, 키-값 등 다양한 데이터 타입 지원
10. 매우 빠른 데이터 적재 (초당 기가바이트 이상)
11. 여러 원천 데이터 통합 적재 가능
12. 스키마 없이 데이터 적재 가능
13. 스트리밍 분석 쿼리 실시간 지원
14. 데이터 갱신도 빠르게 지원
15. 수십억 디멘션, 수조 팩트 테이블 조인 가능 (비정규화 없이)
16. 수십 개 노드에 걸친 복잡한 워크플로우 스케줄링 가능
17. 노드 장애 시 전체 서비스 영향 최소화
18. 장애 복구 및 작업 연속성 보장
19. 혼합 워크로드 (온라인 사용자 쿼리 + 배치/스트리밍 적재) 동시 처리 가능

---

## 5. 빅데이터 아키텍처 2가지

### 5.1 확장된 RDBMS 아키텍처

- 기존 RDBMS 벤더들이 빅데이터 요구사항에 맞게 확장하는 방향
- 벡터, 배열, 하이퍼스트럭쳐 등 다양한 데이터 타입 지원
- 이미지, 비디오, 키-값 쌍, 비정형 텍스트 등 저장 및 처리
- 단순히 BLOB로 저장하는 것 이상으로 **사용자 정의 함수 (UDF)를 DB 내에서 실행 가능**해야 함
- 처리 과정:
    1. 원 데이터에서 의미 있는 정보를 추출
    2. 이를 다시 관계형 로우/칼럼 형태로 변환하여 저장 및 활용

### 5.2 맵리듀스/하둡 아키텍처

- 구글에서 개발한 분산 처리 프레임워크 맵리듀스를 기반으로 하는 아파치 하둡 프로젝트
- 수천 대 서버에서 대용량 데이터 병렬 처리 가능
- 주로 자바로 구현되었으며, 복잡한 사용자 정의 함수 실행에 적합
- 하둡 분산 파일 시스템(HDFS) 위에서 작동하며, Amazon S3 등 다양한 저장소도 지원
- 기존 데이터베이스 벤더들도 하둡 작업과 통합하는 인터페이스를 제공
- 상세 구현은 복잡해 별도 학습 필요

---

## 6. 두 아키텍처 비교

- 각 아키텍처는 장기적으로 공존할 것으로 예상
- 확장된 RDBMS는 기존 BI 및 관계형 데이터에 친화적
- 맵리듀스/하둡은 비정형 대용량 데이터 처리와 복잡한 사용자 정의 함수에 강점

(책 내 그림 21-2 참고)

---

## 7. 정리 및 학습 포인트

- 빅데이터는 단순히 크기뿐 아니라 데이터 형태와 활용 방법에서 기존 데이터와 차별화됨
- 비즈니스 인사이트 창출을 위한 새로운 패러다임 전환임을 명심할 것
- 빅데이터 요구사항은 기존 RDBMS가 갖지 못한 기능과 확장성을 요구함
- 확장된 RDBMS와 맵리듀스/하둡 아키텍처의 특징과 장단점을 이해하고, 실제 업무에 맞게 선택/활용할 준비 필요
- 사용자 정의 함수와 데이터 처리 효율이 핵심 역량임

---

# 빅데이터 우수 사례 학습 노트

---

## 1. 빅데이터 시장과 기존 데이터 웨어하우스 우수 사례 비교

- 빅데이터 시장은 아직 성숙 초기 단계이나 10년간 축적된 경험이 존재
- 관계형 데이터 웨어하우스는 30년간 축적된 우수 사례가 있음
- 데이터 웨어하우스 주요 우수 사례 (Kimball 스타일):
    - 업무요건 기반으로 데이터 선택
    - 단순하고 성능 좋은 UI 집중
    - 다차원적 설계: 현실 세계를 디멘션과 팩트로 분리
    - 원천 데이터 통합을 위한 표준 디멘션 활용
    - 디멘션 이력 관리로 시간에 따른 변화 추적
    - 불변하는 대체 키(대체키)로 디멘션 고정

---

## 2. 빅데이터 환경 관리 우수 사례

### 2.1. 분석환경 지원을 위한 빅데이터 구축

- **목적:** 단순 리포팅 아닌, 다양한 분석환경을 위한 데이터 준비
- 각 단계별, 분석 유형별로 복잡한 분석환경 지원 필요
- 기능: 데이터 적재, 정제, 통합, UI, BI 툴 지원 등
- 생산성 높은 메타 기반 개발 환경 권장 (변화에 유연 대응 가능)

---

### 2.2. 빅데이터로 레거시 환경 구축은 시기상조

- 빅데이터 환경은 빠르게 변화 → 장기적 레거시 구축에 부적합
- 여러 기술과 플랫폼 사이의 균형 유지 필요
- Hadoop, Grid, RDBMS, 클라우드, 메인프레임 등 다양한 접근 방식 병존
- PaaS 형태로 툴 간 호환 조합하는 플랫폼이 효과적
- 하둡은 유연한 ETL 처리 플랫폼으로 인식 → 여러 툴이 동시에 접근 가능
- 재프로그램 부담을 줄이려면 메타 기반 개발 환경 권장

---

### 2.3. 샌드박스 결과를 빅데이터에 통합

- 데이터 과학자가 자유롭게 실험 → 성공 시 IT팀이 운영 환경으로 재구현
- 다양한 언어와 툴 허용하되, 운영은 표준 기술로 유지
- 예: 데이터 과학자는 R 코드로 하둡 샌드박스에서 작업 → IT는 ETL 툴로 재배포
- 확장성, 가용성, 보안성 갖춘 환경에 재배포하여 운영

---

### 2.4. 단순한 애플리케이션부터 빅데이터 적용 시작

- 초기 리스크 낮추기 위해 백업/복구 같은 단순 업무에 Hadoop 적용 권장
- Hadoop은 비정형부터 정형 데이터까지 저장 및 조회 가능
- 기존 애플리케이션 사용 중단 시 데이터 이전용으로 유용

---

## 3. 아키텍처 측면 우수 사례

### 3.1. 데이터 고속도로(Data Highway) 설계

- 다층의 시간차별 데이터 캐시 구조 계획 (최대 5개 계층)
- 각 계층별 역할:

| 계층 | 예시 및 기능 |
| --- | --- |
| 원천 | 신용카드 부정탐지, 사이버공격 탐지 등 실시간 복잡 이벤트 처리(CEP) |
| 실시간 적용 | 웹광고 선정, 개인화 프로모션, 온라인 게임 모니터링 |
| 비즈니스 활동 리포팅 | 핵심성과지표 대시보드, 버그 추적, 고객 서비스 포탈, 모바일 판매 애플리케이션 |
| 상위 관리자 리포팅 | 전술적 리포팅, 프로모션 추적, SNS 기반 모니터링 |
| 데이터 웨어하우스 | 시계열 분석, 대용량 임시 데이터, 마스터 데이터 관리 |
- 각 계층은 물리적으로 분리 가능
- ETL로 원천부터 각 계층 데이터 이동
- 역방향 흐름도 가능 (후에 심화 학습 필요)
- 데이터 종류 다양 (텍스트, 이미지, 그래프 등)

---

### 3.2. 빅데이터로부터 측정값(팩트) 추출

- 비정형 데이터 → 정량화된 수치로 변환해 다음 단계로 전달
- 예: 트윗 텍스트 분석 → 참여도, 이슈 해결율, 만족도, 토픽 트렌드 등 수치화
- 측정값을 만들어 데이터 웨어하우스 등 후속 시스템에 입력

---

### 3.3. 포괄적인 에코시스템 구축

- 기존 RDBMS, 문서, 이메일, SNS 등 다양한 원천 데이터 통합
- SNS, 모바일, 자동화 탐지 프로세스 등 새로운 데이터 채널 포함
- 대규모 조직에서 보안 SNS 구축 후 의미 있는 쿼리 가능한 데이터로 저장
- 모든 정보는 하둡에 저장, 다차원 모델링, 백업·복구 처리
- 실무 시 빅데이터 기반 통합 커뮤니케이션 플랫폼으로 응용 가능

---

### 3.4. 데이터 품질 계획

- 시간차가 적을수록 데이터 품질은 낮아지는 트레이드오프 존재
- 빠른 데이터 정제는 개별 속성 위주 → 복합 관계 테스트는 시간 필요
- 장기적 보고서(일별 등)는 완결된 데이터 필요 → 미완료/거절 거래 제외
- 실무 적용 시: 단계별 품질 향상 전략 수립 필요

---

### 3.5. 가능한 빨리 데이터에 가치 부여

- 데이터 필터링, 정제, 불필요한 부분 제거, 표준화, 연결, 조인, 진단 등 최대한 앞 단계에서 처리
- 이로써 후속 시스템 및 분석에 고품질 데이터 제공 가능

---

# 데이터 모델링 및 데이터 거버넌스 우수 사례 학습 노트

---

## 1. 데이터 모델링 측면의 우수 사례

### 1-1. 다차원적으로 생각하라 (Think Multidimensionally)

- 세상을 **디멘션(Dimension)** 과 **팩트(Fact)** 로 나누어 이해하는 것.
- 현업 사용자는 고객, 상품, 장소, 시간 등 디멘션 개념을 자연스럽게 인지함.
- 다차원화는 여러 데이터 원천을 통합하는 핵심 방법.
- 각 원천에서 디멘션을 식별하고, 가장 상세한 데이터에 연결해야 함.
- **빅데이터 환경에서는 자동화된 다차원화가 필요**하며, 데이터는 가능한 한 실시간에 가깝게 다차원화 되어야 함.
- 예시: 트위터 문장 ‘와! 이거 멋진데’ → 고객, 장소, 상품, 시장 상황, 날씨 등 다양한 디멘션으로 분해 가능.

---

### 1-2. 표준 디멘션을 통해 데이터 원천을 통합하라 (Integrate Using Standard Dimensions)

- 표준 디멘션은 서로 다른 데이터 원천을 통합하고 분석 가능하게 함.
- 예: 고객 디멘션은 여러 원천에서 변형되어 존재하지만, 공통된 전사적 속성을 정의하여 통합 가능.
- 공통 속성 예: 인구통계학적 분류.
- 점진적이고 애자일하게 표준 디멘션을 적용하며 기존 분석 애플리케이션은 계속 운영 가능.

---

### 1-3. 영속성을 보장하는 대체 키를 사용하여 디멘션과 연결하라 (Use Surrogate Keys)

- 원천 시스템의 키(Primary Key)를 그대로 사용하지 말 것.
- 원천 키는 호환성 문제, 관리 문제, 변경 위험이 큼.
- **대체 키(Surrogate Key)** 는 데이터 웨어하우스에서 관리하며, 변경되지 않는 영속적인 키.
- 대체 키는 단순한 정수형 시퀀스 또는 해시값으로 의미를 갖지 않는 식별자.
- 대체 키 덕분에 데이터 추출, 적재, 통합 프로세스가 안정적이고 일관성 있게 수행됨.

---

### 1-4. 정형 데이터와 비정형 데이터를 통합하라 (Integrate Structured & Unstructured Data)

- 빅데이터는 정형 데이터뿐만 아니라 이미지, 텍스트, SNS 등 비정형 데이터 포함.
- 표준 디멘션과 영속 대체 키가 있으면 다양한 형태 데이터의 통합 분석 가능.
- 예시: 의학 연구 데이터에서 환자 인구통계학 + 이미지(X-ray) + 의사 노트 + SNS 의견 결합 가능.

---

### 1-5. 디멘션 이력 관리를 사용하라 (Use Slowly Changing Dimensions)

- 시간에 따라 변하는 속성을 추적하기 위한 기법.
- 전통 DW뿐 아니라 빅데이터 환경에서도 중요.
- 디멘션 이력 관리 사례는 조달 등 업무에서 유용하게 적용됨.

---

### 1-6. 분석 시점에 데이터 구조를 선언하라 (Declare Schema at Query Time)

- 빅데이터 적재 시점에는 데이터 구조를 미리 선언하지 않아도 됨 (Schema-on-Read).
- 이점: 데이터 구조 불명확, 가변적 내용, 강제 변경 부담 회피 가능.
- 여러 분석가가 같은 데이터를 각자 다른 방식으로 해석 가능.
- 단점: 인덱스 생성이 어렵지만 빅데이터 분석 알고리즘은 보통 전체 데이터 처리.
- 전통 RDBMS 방식과 다르지만 상호 보완적임.

---

### 1-7. 단순한 키-값 구조로 데이터를 적재하라 (Store Data in Simple Key-Value Format)

- 빅데이터 원천에는 예상치 못한 다양한 데이터가 많아, 복잡한 구조 선언이 어려움.
- 키-값 구조는 예상 못한 데이터도 쉽게 적재 가능.
- 예시: 고객이 ‘희귀 우표만 달러어치’라는 데이터를 입력해도 적재 가능.
- 많은 맵리듀스 프로그래밍은 키-값 구조를 요구.

---

### 1-8. 데이터 가상화를 통해 빠르게 프로토타이핑 하라 (Use Data Virtualization)

- 데이터 가상화는 물리적 데이터 위에 다양한 논리적 스키마를 선언하는 기술.
- 빠른 스키마 변경과 프로토타이핑에 적합.
- 단점: 실행 시 컴퓨팅 자원 소모(반면 ETL은 사전 물리 테이블 생성).
- 이상적인 전략: 가상 스키마로 테스트 후 성능 개선 필요시 물리 테이블로 전환.

---

## 2. 데이터 거버넌스 관련 우수 사례

### 2-1. 빅데이터 거버넌스란 것은 별개로 없다 (No Separate Big Data Governance)

- 빅데이터 거버넌스는 기업 전체 데이터 거버넌스의 확장 개념이어야 함.
- 개인정보 보호, 보안, 규제 준수, 데이터 품질, 메타데이터 관리, 마스터 데이터 관리, 업무 용어 사전 포함.

---

### 2-2. 거버넌스를 적용하기 전에 데이터를 다차원화하라 (Apply Governance After Multidimensional Structuring)

- 빅데이터는 예상치 못한 내용과 초고속 적재 환경이라 거버넌스 적용이 어렵다.
- 데이터 파이프라인에서 최대한 앞 단계에서 다차원화를 수행해 데이터 분류 및 관리 용이.
- 데이터 통합 및 품질 관리를 위해 다차원화는 거버넌스 필수 선행 단계임.

---

### 2-3. 개인정보 보호가 가장 중요한 거버넌스 주제이다 (Privacy is the Top Governance Priority)

- 개인 식별 가능한 정보를 다룰 때는 개인정보 보호가 핵심.
- 비즈니스 위험 최소화를 위해 개인정보 보호 정책과 절차가 반드시 포함돼야 함.

---

# 마무리

- 이 우수 사례들은 전통적인 데이터 웨어하우스 기법과 빅데이터 환경을 연결하는 다리 역할을 합니다.
- **다차원적 사고, 표준 디멘션, 영속 키, 데이터 가상화, 키-값 저장 방식, 그리고 강력한 거버넌스 체계가 핵심**입니다.
- 단계별로 적용하고, 점진적 개선과 자동화를 병행하면 빅데이터 환경에서 더욱 강력한 데이터 시스템을 구축할 수 있습니다.